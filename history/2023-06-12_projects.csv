,name,github_id,labels,category,github_url,homepage,license,created_at,updated_at,last_commit_pushed_at,commit_count,recent_commit_count,fork_count,watchers_count,pr_count,open_issue_count,closed_issue_count,star_count,latest_stable_release_published_at,latest_stable_release_number,github_release_downloads,monthly_downloads,release_count,description,contributor_count,projectrank,show,projectrank_placing,new_addition,dependent_project_count,github_dependent_project_count
0,Triton Inference Server,triton-inference-server/server,"['tensorflow', 'pytorch']",model-serving,https://github.com/triton-inference-server/server,https://github.com/triton-inference-server/server,BSD-3-Clause,2018-10-04 21:10:30,2023-06-12 04:42:57,2023-06-11 19:56:38,3045.0,122.0,1179.0,122.0,3059.0,267.0,2533.0,5462.0,2023-05-31 00:18:03,2.34.0,195253.0,3550.0,55.0,The Triton Inference Server provides an optimized cloud and edge inferencing solution.,104.0,29,True,1.0,True,,
1,TensorFlow Serving,tensorflow/serving,['tensorflow'],others,https://github.com/tensorflow/serving,https://github.com/tensorflow/serving,Apache-2.0,2016-01-26 21:48:20,2023-06-08 21:52:39,2023-06-08 21:52:36,7657.0,106.0,2103.0,241.0,721.0,45.0,1373.0,5872.0,2023-05-02 04:07:15,2.12.1,,,100.0,"A flexible, high-performance serving system for machine learning models.",213.0,28,True,1.0,True,2.0,2.0
2,BentoML,https://github.com/bentoml/BentoML,"['tensorflow', 'pytorch']",others,,{},,,,,,,,,,,,,,,,,,,,0,False,,True,,
